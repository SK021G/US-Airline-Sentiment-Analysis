{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d28da9a3",
   "metadata": {},
   "source": [
    "### Step 1: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c386a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41347494",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e823659a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully! Here are the first 5 rows:\n",
      "                                                text airline_sentiment\n",
      "0                @VirginAmerica What @dhepburn said.           neutral\n",
      "1  @VirginAmerica plus you've added commercials t...          positive\n",
      "2  @VirginAmerica I didn't today... Must mean I n...           neutral\n",
      "3  @VirginAmerica it's really aggressive to blast...          negative\n",
      "4  @VirginAmerica and it's a really big bad thing...          negative\n",
      "\n",
      "Here's how many tweets we have for each sentiment:\n",
      "airline_sentiment\n",
      "negative    9178\n",
      "neutral     3099\n",
      "positive    2363\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "file_path = \"C:\\\\Users\\\\Lenovo\\\\Downloads\\\\archive (13)\\\\Tweets.csv\"\n",
    "# We use a try-except block to handle the error if the file isn't found.\n",
    "try:\n",
    "    full_dataset = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Make sure it's in the same folder as your script.\")\n",
    "    exit()\n",
    "\n",
    "# We only need two columns: the tweet's text and its sentiment.\n",
    "data = full_dataset[['text', 'airline_sentiment']]\n",
    "print(\"Dataset loaded successfully! Here are the first 5 rows:\")\n",
    "print(data.head())\n",
    "print(\"\\nHere's how many tweets we have for each sentiment:\")\n",
    "print(data['airline_sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00772d6e",
   "metadata": {},
   "source": [
    "### Step 3: Clean the Tweet Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e25baff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets are messy! They have @mentions, links, and symbols.\n",
    "# We'll create a function to clean this up.\n",
    "def clean_tweet_text(text):\n",
    "    # Remove usernames (e.g., \"@virginamerica\")\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove website links\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove characters that aren't letters or spaces\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Make all text lowercase\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55e868f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning complete! Here's the same 5 rows after cleaning:\n",
      "                                                text airline_sentiment  \\\n",
      "0                @VirginAmerica What @dhepburn said.           neutral   \n",
      "1  @VirginAmerica plus you've added commercials t...          positive   \n",
      "2  @VirginAmerica I didn't today... Must mean I n...           neutral   \n",
      "3  @VirginAmerica it's really aggressive to blast...          negative   \n",
      "4  @VirginAmerica and it's a really big bad thing...          negative   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0                                         what  said  \n",
      "1   plus youve added commercials to the experienc...  \n",
      "2   i didnt today must mean i need to take anothe...  \n",
      "3   its really aggressive to blast obnoxious ente...  \n",
      "4            and its a really big bad thing about it  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5692\\2933492430.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['cleaned_text'] = data['text'].apply(clean_tweet_text)\n"
     ]
    }
   ],
   "source": [
    "# Apply our cleaning function to every tweet in the 'text' column.\n",
    "data['cleaned_text'] = data['text'].apply(clean_tweet_text)\n",
    "print(\"Text cleaning complete! Here's the same 5 rows after cleaning:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85363d94",
   "metadata": {},
   "source": [
    "### Step 4: Convert Text to Numbers (Tokenization & Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e966f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A neural network can only understand numbers, not words.\n",
    "# So, we need to convert our cleaned text into numerical sequences.\n",
    "\n",
    "# We'll set some limits for our model.\n",
    "max_words_in_vocab = 5000  # The model will only learn the top 5,000 most common words.\n",
    "max_tweet_length = 100     # Each tweet will be treated as if it has 100 words (we'll add padding).\n",
    "\n",
    "# This Tokenizer object learns the vocabulary from our tweets.\n",
    "tokenizer = Tokenizer(num_words=max_words_in_vocab)\n",
    "tokenizer.fit_on_texts(data['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9584d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we convert the text into sequences of numbers.\n",
    "sequences = tokenizer.texts_to_sequences(data['cleaned_text'])\n",
    "\n",
    "# Since all tweets have different lengths, we need to \"pad\" them with zeros\n",
    "# so they are all the same length (100 in this case).\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_tweet_length)\n",
    "X = padded_sequences # Our features (the tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d50809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is now ready for the model!\n",
      "Shape of our features (X): (14640, 100)\n",
      "Shape of our labels (Y): (14640, 3)\n"
     ]
    }
   ],
   "source": [
    "# We do the same for the labels (the sentiment).\n",
    "# 'get_dummies' converts the text labels ('positive', 'negative', 'neutral')\n",
    "# into a \"one-hot encoded\" format, like [0, 0, 1] for positive.\n",
    "labels = pd.get_dummies(data['airline_sentiment'])\n",
    "Y = labels.values # Our labels\n",
    "label_names = labels.columns.tolist() # Store the names for later\n",
    "\n",
    "print(\"Data is now ready for the model!\")\n",
    "print(\"Shape of our features (X):\", X.shape)\n",
    "print(\"Shape of our labels (Y):\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6226b14",
   "metadata": {},
   "source": [
    "### Step 5: Split the Data for Training and Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5362f9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split complete.\n"
     ]
    }
   ],
   "source": [
    "# We'll use 80% of the data to train our model and 20% to test how well it learned.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(\"Data split complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba5beb2",
   "metadata": {},
   "source": [
    "### Step 6: Build the Neural Network (RNN Model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d45501f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We'll create a simple, sequential model, where each layer feeds into the next.\n",
    "model = Sequential()\n",
    "# Layer 1: Embedding Layer. This layer learns meaningful vector representations for each word.\n",
    "model.add(Embedding(input_dim=max_words_in_vocab, output_dim=32, input_length=max_tweet_length))\n",
    "# Layer 2: SimpleRNN Layer. This layer processes the sequence of word vectors.\n",
    "model.add(SimpleRNN(32))\n",
    "# Layer 3: Output Layer. This layer gives us the final prediction.\n",
    "# It has 3 neurons (one for each sentiment) and 'softmax' activation to give a probability for each.\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# \"Compile\" the model with settings for how it should learn.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Print a summary of our model's architecture.\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eccdf3a",
   "metadata": {},
   "source": [
    "### Step 7: Train the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a3b2a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.6337 - loss: 0.8446 - val_accuracy: 0.7462 - val_loss: 0.6029\n",
      "Epoch 2/5\n",
      "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.7972 - loss: 0.5281 - val_accuracy: 0.7613 - val_loss: 0.5795\n",
      "Epoch 3/5\n",
      "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8752 - loss: 0.3707 - val_accuracy: 0.7640 - val_loss: 0.6130\n",
      "Epoch 4/5\n",
      "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9353 - loss: 0.2209 - val_accuracy: 0.7579 - val_loss: 0.7091\n",
      "Epoch 5/5\n",
      "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9583 - loss: 0.1389 - val_accuracy: 0.7305 - val_loss: 0.8280\n",
      "Model training complete!\n"
     ]
    }
   ],
   "source": [
    "# We \"fit\" the model to our training data.\n",
    "# An \"epoch\" is one full pass through the entire training dataset.\n",
    "model.fit(X_train, Y_train, epochs=5, batch_size=32, validation_data=(X_test, Y_test))\n",
    "print(\"Model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2102bb95",
   "metadata": {},
   "source": [
    "### Step 8: Create a Prediction Function and Test in Real-Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773fb804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter a tweet to analyze (or type 'quit' to exit): Splendid\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
      "\n",
      "Prediction: NEUTRAL\n",
      "Confidence: 51.73%\n",
      "----------------------------------------\n",
      "\n",
      "Enter a tweet to analyze (or type 'quit' to exit): It's extraordinary\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      "Prediction: POSITIVE\n",
      "Confidence: 54.26%\n",
      "----------------------------------------\n",
      "\n",
      "Enter a tweet to analyze (or type 'quit' to exit): The flight crashed\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      "Prediction: NEGATIVE\n",
      "Confidence: 40.82%\n",
      "----------------------------------------\n",
      "\n",
      "Enter a tweet to analyze (or type 'quit' to exit): Quick service but bad washrooms\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\n",
      "Prediction: POSITIVE\n",
      "Confidence: 79.16%\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_tweet_sentiment(tweet_text):\n",
    "    # First, clean the input text just like we did for the training data.\n",
    "    cleaned_text = clean_tweet_text(tweet_text)\n",
    "    # Convert the cleaned text to a numerical sequence.\n",
    "    sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
    "    # Pad the sequence so it's the correct length.\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_tweet_length)\n",
    "    \n",
    "    # Get the model's prediction.\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    \n",
    "    # The prediction is an array of probabilities, e.g., [0.1, 0.2, 0.7].\n",
    "    # We find the index of the highest probability.\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    # Use the index to get the sentiment name.\n",
    "    predicted_sentiment = label_names[predicted_index]\n",
    "    # Also get the confidence score (the highest probability).\n",
    "    confidence = prediction[0][predicted_index]\n",
    "    \n",
    "    return predicted_sentiment, confidence\n",
    "\n",
    "# A loop to let the user enter tweets continuously.\n",
    "while True:\n",
    "    user_input = input(\"\\nEnter a tweet to analyze (or type 'quit' to exit): \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "        \n",
    "    sentiment, confidence = predict_tweet_sentiment(user_input)\n",
    "    print(f\"\\nPrediction: {sentiment.upper()}\")\n",
    "    print(f\"Confidence: {confidence:.2%}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27bfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
